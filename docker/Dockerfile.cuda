# translate-dub CUDA Development Environment
# Base: NVIDIA CUDA 12.1 + Ubuntu 22.04
# Usage: docker build -f docker/Dockerfile.cuda -t translate-dub:cuda .

FROM nvidia/cuda:12.1.1-devel-ubuntu22.04

# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    # Python build dependencies
    software-properties-common \
    build-essential \
    curl \
    git \
    git-lfs \
    # Audio processing
    sox \
    libsox-dev \
    libsox-fmt-all \
    ffmpeg \
    libsndfile1 \
    # Utilities
    vim \
    tmux \
    htop \
    && rm -rf /var/lib/apt/lists/*

# Install Python 3.12 (best CUDA/PyTorch compatibility)
RUN add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
    python3.12 \
    python3.12-venv \
    python3.12-dev \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.12 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1

# Install uv package manager
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.local/bin:${PATH}"

# Set up git-lfs for model downloads
RUN git lfs install

# Create working directory
WORKDIR /workspace

# Copy pyproject for dependency installation
COPY pyproject.cuda.toml pyproject.toml
COPY Qwen3-TTS/ Qwen3-TTS/

# Pre-install dependencies to cache in Docker layer
# This makes subsequent builds faster
RUN uv venv && \
    uv sync --no-dev

# Set environment variables for CUDA
ENV CUDA_HOME=/usr/local/cuda
ENV PATH="${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# HuggingFace cache directory (can be mounted as volume)
ENV HF_HOME=/root/.cache/huggingface
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface

# Default command
CMD ["/bin/bash"]
